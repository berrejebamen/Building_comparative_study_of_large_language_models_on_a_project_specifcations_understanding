{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfdbaa42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ktrapeznikov/albert-xlarge-v2-squad-v2 were not used when initializing AlbertForQuestionAnswering: ['albert.pooler.weight', 'albert.pooler.bias']\n",
      "- This IS expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlbertForQuestionAnswering(\n",
       "  (albert): AlbertModel(\n",
       "    (embeddings): AlbertEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): AlbertTransformer(\n",
       "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=2048, bias=True)\n",
       "      (albert_layer_groups): ModuleList(\n",
       "        (0): AlbertLayerGroup(\n",
       "          (albert_layers): ModuleList(\n",
       "            (0): AlbertLayer(\n",
       "              (full_layer_layer_norm): LayerNorm((2048,), eps=1e-12, elementwise_affine=True)\n",
       "              (attention): AlbertAttention(\n",
       "                (query): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "                (key): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "                (value): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "                (attention_dropout): Dropout(p=0.1, inplace=False)\n",
       "                (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "                (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "                (LayerNorm): LayerNorm((2048,), eps=1e-12, elementwise_affine=True)\n",
       "              )\n",
       "              (ffn): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "              (ffn_output): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "              (activation): GELUActivation()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import libraries and initialize the model\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers import (\n",
    "    AlbertConfig,\n",
    "    AlbertForQuestionAnswering,\n",
    "    AlbertTokenizer,\n",
    "    squad_convert_examples_to_features\n",
    ")\n",
    "\n",
    "from transformers.data.processors.squad import SquadResult, SquadV2Processor, SquadExample\n",
    "\n",
    "from transformers.data.metrics.squad_metrics import compute_predictions_logits\n",
    "\n",
    "# READER NOTE: Set this flag to use own model, or use pretrained model in the Hugging Face repository\n",
    "use_own_model = False\n",
    "\n",
    "if use_own_model:\n",
    "  model_name_or_path = \"/content/model_output\"\n",
    "else:\n",
    "  model_name_or_path = \"ktrapeznikov/albert-xlarge-v2-squad-v2\"\n",
    "\n",
    "output_dir = \"\"\n",
    "\n",
    "# Config\n",
    "n_best_size = 1\n",
    "max_answer_length = 100\n",
    "do_lower_case = True\n",
    "null_score_diff_threshold = 0.0\n",
    "\n",
    "def to_list(tensor):\n",
    "    return tensor.detach().cpu().tolist()\n",
    "\n",
    "# Setup model\n",
    "config_class, model_class, tokenizer_class = (\n",
    "    AlbertConfig, AlbertForQuestionAnswering, AlbertTokenizer)\n",
    "config = config_class.from_pretrained(model_name_or_path)\n",
    "tokenizer = tokenizer_class.from_pretrained(\n",
    "    model_name_or_path, do_lower_case=True)\n",
    "model = model_class.from_pretrained(model_name_or_path, config=config)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ed1fc2",
   "metadata": {},
   "source": [
    "# Define Function to run prediction \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a63a80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_prediction(question, context_text):\n",
    "    \"\"\"Setup function to compute predictions\"\"\"\n",
    "    examples = []\n",
    "\n",
    "    for i, question_text in enumerate(question):\n",
    "        example = SquadExample(\n",
    "            qas_id=str(i),\n",
    "            question_text=question_text,\n",
    "            context_text=context_text,\n",
    "            answer_text=None,\n",
    "            start_position_character=None,\n",
    "            title=\"Predict\",\n",
    "            is_impossible=False,\n",
    "            answers=None,\n",
    "        )\n",
    "\n",
    "        examples.append(example)\n",
    "\n",
    "    features, dataset = squad_convert_examples_to_features(\n",
    "        examples=examples,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=384,\n",
    "        doc_stride=128,\n",
    "        max_query_length=64,\n",
    "        is_training=False,\n",
    "        return_dataset=\"pt\",\n",
    "        threads=1,\n",
    "    )\n",
    "\n",
    "    eval_sampler = SequentialSampler(dataset)\n",
    "    eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=10)\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    for batch in eval_dataloader:\n",
    "        model.eval()\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs = {\n",
    "                \"input_ids\": batch[0],\n",
    "                \"attention_mask\": batch[1],\n",
    "                \"token_type_ids\": batch[2],\n",
    "            }\n",
    "\n",
    "            example_indices = batch[3]\n",
    "\n",
    "            outputs = model(**inputs).values()\n",
    "\n",
    "            for i, example_index in enumerate(example_indices):\n",
    "                eval_feature = features[example_index.item()]\n",
    "                unique_id = int(eval_feature.unique_id)\n",
    "\n",
    "                output = [to_list(output[i]) for output in outputs]\n",
    "\n",
    "                start_logits, end_logits = output\n",
    "                result = SquadResult(unique_id, start_logits, end_logits)\n",
    "                all_results.append(result)\n",
    "\n",
    "    output_prediction_file = \"predictions.json\"\n",
    "    output_nbest_file = \"nbest_predictions.json\"\n",
    "    output_null_log_odds_file = \"null_predictions.json\"\n",
    "\n",
    "    predictions = compute_predictions_logits(\n",
    "        examples,\n",
    "        features,\n",
    "        all_results,\n",
    "        n_best_size,\n",
    "        max_answer_length,\n",
    "        do_lower_case,\n",
    "        output_prediction_file,\n",
    "        output_nbest_file,\n",
    "        output_null_log_odds_file,\n",
    "        False,  # verbose_logging\n",
    "        True,  # version_2_with_negative\n",
    "        null_score_diff_threshold,\n",
    "        tokenizer,\n",
    "    )\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe063cc4",
   "metadata": {},
   "source": [
    "# Reading Context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b74be54",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data2.txt', 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b24cb4c",
   "metadata": {},
   "source": [
    "# Preparing metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d4cdb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_evaluation.\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate.meteor_score import single_meteor_score\n",
    "from nltk.translate.meteor_score import single_meteor_score\n",
    "from nltk.translate.bleu_score import sentence_bleu ,SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "import pandas as pd\n",
    "def calculate_rouge2_score(reference, candidate):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge2'], use_stemmer=True)\n",
    "    scores = scorer.score(reference, candidate)\n",
    "    return scores['rouge2'].fmeasure\n",
    "\n",
    "def calculate_bleu_score(reference, hypothesis):\n",
    "    # Tokenize the reference and hypothesis translations\n",
    "    reference_tokens = nltk.word_tokenize(reference.lower())\n",
    "    hypothesis_tokens = nltk.word_tokenize(hypothesis.lower())\n",
    "\n",
    "    # Calculate BLEU score using NLTK's corpus BLEU implementation\n",
    "    # We use weights=(1, 0, 0, 0) for unigram precision (BLEU-1)\n",
    "    bleu_score = nltk.translate.bleu_score.sentence_bleu([reference_tokens], hypothesis_tokens, weights=(1, 0, 0, 0))\n",
    "    \n",
    "    return bleu_score\n",
    "def load_existing_results(file_path):\n",
    "    try:\n",
    "        existing_df = pd.read_csv(file_path)\n",
    "        return existing_df\n",
    "    except FileNotFoundError:\n",
    "        return pd.DataFrame(columns=[\"Question\", \"True Answer\", \"Predicted Answer\", \"BLEU Score\", \"ROUGE-2 Score\"])\n",
    "def save_dataframe_to_csv(dataframe, file_path):\n",
    "    dataframe.to_csv(file_path, index=False)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e5402e",
   "metadata": {},
   "source": [
    "# Runing Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9980ebd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your question (or type 'exit' to quit): exit\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "result_file_path = \"output2.csv\"  # Adjust the file path as needed\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "existing_results_df = load_existing_results(result_file_path)\n",
    "while True:\n",
    "    # Get user input\n",
    "    user_question = input(\"Enter your question (or type 'exit' to quit): \")\n",
    "    \n",
    "    if user_question.lower() == \"exit\":\n",
    "        print(\"Exiting...\")\n",
    "        break\n",
    "    \n",
    "    true_answer = input(\"Enter the true answer or type 'skip': \")\n",
    "    \n",
    "    if true_answer.lower() == \"skip\":\n",
    "        # Run prediction\n",
    "        predictions = run_prediction([user_question], text)\n",
    "        \n",
    "        # Get predicted answer\n",
    "        predicted_answer = list(predictions.values())[0]\n",
    "        \n",
    "        # Print only the predicted answer\n",
    "        print(\"Predicted Answer:\", predicted_answer)\n",
    "    else:\n",
    "        # Run prediction\n",
    "        predictions = run_prediction([user_question], text)\n",
    "        \n",
    "        # Get predicted answer and calculate scores\n",
    "        predicted_answer = list(predictions.values())[0]\n",
    "        bleu_score = calculate_bleu_score(predicted_answer.capitalize(), true_answer.capitalize())\n",
    "        rouge2_score = calculate_rouge2_score(predicted_answer.capitalize(), true_answer.capitalize())\n",
    "        new_data = {\n",
    "                \"Question\": user_question.capitalize(),\n",
    "                \"Predicted Answer\": predicted_answer.capitalize(),\n",
    "                \"True Answer\": true_answer.capitalize(),\n",
    "                \"BLEU Score\": bleu_score,\n",
    "                \"ROUGE-2 Score\": rouge2_score\n",
    "            }\n",
    "            \n",
    "        existing_results_df = pd.concat([existing_results_df, pd.DataFrame([new_data])], ignore_index=True)\n",
    "        save_dataframe_to_csv(existing_results_df, result_file_path)\n",
    "            \n",
    "        # Print results\n",
    "        print(\"Predicted Answer:\", predicted_answer)\n",
    "        print(\"True Answer:\", true_answer)\n",
    "        print(\"BLEU Score:\", bleu_score)\n",
    "        print(\"ROUGE Score:\", rouge2_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c44c17",
   "metadata": {},
   "source": [
    "# ALBERT FINAL RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29e255a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>True Answer</th>\n",
       "      <th>Predicted Answer</th>\n",
       "      <th>BLEU Score</th>\n",
       "      <th>ROUGE-2 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is etl</td>\n",
       "      <td>A data integration process that combines data ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is sla</td>\n",
       "      <td>A contract between a service provider and its ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What does etl stand for</td>\n",
       "      <td>Extract , transform , load</td>\n",
       "      <td>Extract, transform, and load,</td>\n",
       "      <td>0.670320</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What does sla stand for</td>\n",
       "      <td>Service-level agreement</td>\n",
       "      <td>Service-level agreement</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A sla is a contract between who and who</td>\n",
       "      <td>A service provider and its customers</td>\n",
       "      <td>A service provider and its customers</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>How might the aggregation rule's implementatio...</td>\n",
       "      <td>It could change to be a business rule in advan...</td>\n",
       "      <td>It could change to be a business rule</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Where will the unaccounted events dashboard be...</td>\n",
       "      <td>The unaccounted events dashboard will appear u...</td>\n",
       "      <td>In the second position under the accounting ma...</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.516129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>how can the user select multiple entities for...</td>\n",
       "      <td>Using the check-boxes displayed besides the ev...</td>\n",
       "      <td>Using the check-boxes displayed besides the ev...</td>\n",
       "      <td>0.882497</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Who define the accounting period duration</td>\n",
       "      <td>The airline</td>\n",
       "      <td>The accounting period duration is a parameter ...</td>\n",
       "      <td>0.002479</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Who defines the accounting period duration</td>\n",
       "      <td>The accounting period duration is a parameter ...</td>\n",
       "      <td>The accounting period duration is a parameter ...</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Question  \\\n",
       "0                                         What is etl   \n",
       "1                                         What is sla   \n",
       "2                             What does etl stand for   \n",
       "3                             What does sla stand for   \n",
       "4             A sla is a contract between who and who   \n",
       "..                                                ...   \n",
       "85  How might the aggregation rule's implementatio...   \n",
       "86  Where will the unaccounted events dashboard be...   \n",
       "87   how can the user select multiple entities for...   \n",
       "88          Who define the accounting period duration   \n",
       "89         Who defines the accounting period duration   \n",
       "\n",
       "                                          True Answer  \\\n",
       "0   A data integration process that combines data ...   \n",
       "1   A contract between a service provider and its ...   \n",
       "2                          Extract , transform , load   \n",
       "3                             Service-level agreement   \n",
       "4                A service provider and its customers   \n",
       "..                                                ...   \n",
       "85  It could change to be a business rule in advan...   \n",
       "86  The unaccounted events dashboard will appear u...   \n",
       "87  Using the check-boxes displayed besides the ev...   \n",
       "88                                        The airline   \n",
       "89  The accounting period duration is a parameter ...   \n",
       "\n",
       "                                     Predicted Answer  BLEU Score  \\\n",
       "0                                                 NaN    0.000000   \n",
       "1                                                 NaN    0.000000   \n",
       "2                       Extract, transform, and load,    0.670320   \n",
       "3                             Service-level agreement    1.000000   \n",
       "4                A service provider and its customers    1.000000   \n",
       "..                                                ...         ...   \n",
       "85              It could change to be a business rule    0.727273   \n",
       "86  In the second position under the accounting ma...    0.375000   \n",
       "87  Using the check-boxes displayed besides the ev...    0.882497   \n",
       "88  The accounting period duration is a parameter ...    0.002479   \n",
       "89  The accounting period duration is a parameter ...    0.933333   \n",
       "\n",
       "    ROUGE-2 Score  \n",
       "0        0.000000  \n",
       "1        0.000000  \n",
       "2        0.400000  \n",
       "3        1.000000  \n",
       "4        1.000000  \n",
       "..            ...  \n",
       "85       0.823529  \n",
       "86       0.516129  \n",
       "87       1.000000  \n",
       "88       0.142857  \n",
       "89       1.000000  \n",
       "\n",
       "[90 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"output2.csv\")  \n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfc4f3a",
   "metadata": {},
   "source": [
    "# Randomly picking 10 rows from the output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "507917f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>True Answer</th>\n",
       "      <th>Predicted Answer</th>\n",
       "      <th>BLEU Score</th>\n",
       "      <th>ROUGE-2 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>What is the purpose of manual task management ...</td>\n",
       "      <td>Manual task management methods allow either fo...</td>\n",
       "      <td>Allow either for operators to pick tasks from ...</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>When the settlement is considered \"settled\"</td>\n",
       "      <td>When it has been successfully matched to one o...</td>\n",
       "      <td>When it has been successfully matched to one o...</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is load test</td>\n",
       "      <td>Load test is the objective is to ensure that l...</td>\n",
       "      <td>Load test is the objective is to ensure that l...</td>\n",
       "      <td>0.963640</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>What is the primary objective of initiating th...</td>\n",
       "      <td>The primary objective of initiating the disput...</td>\n",
       "      <td>This step aims to facilitate a negotiation or ...</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Where will the unaccounted events dashboard be...</td>\n",
       "      <td>The unaccounted events dashboard will appear u...</td>\n",
       "      <td>In the second position under the accounting ma...</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.516129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>How might the aggregation rule's implementatio...</td>\n",
       "      <td>It could change to be a business rule in advan...</td>\n",
       "      <td>It could change to be a business rule</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>How is the settlement of each form of payment ...</td>\n",
       "      <td>Is settled by a specific acquirers</td>\n",
       "      <td>Settled by a specific acquirers</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Where will the unaccounted events dashboard be...</td>\n",
       "      <td>Under the name unaccounted events and will be ...</td>\n",
       "      <td>Second position under the accounting main title</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.521739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>What are the components that make up the relat...</td>\n",
       "      <td>The account, the account name, signing, amount...</td>\n",
       "      <td>The account, the account name, signing, amount...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>What protocol is the file's transmission based...</td>\n",
       "      <td>Sftp</td>\n",
       "      <td>Sftp</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Question  \\\n",
       "38  What is the purpose of manual task management ...   \n",
       "19        When the settlement is considered \"settled\"   \n",
       "8                                   What is load test   \n",
       "79  What is the primary objective of initiating th...   \n",
       "86  Where will the unaccounted events dashboard be...   \n",
       "85  How might the aggregation rule's implementatio...   \n",
       "61  How is the settlement of each form of payment ...   \n",
       "53  Where will the unaccounted events dashboard be...   \n",
       "43  What are the components that make up the relat...   \n",
       "30  What protocol is the file's transmission based...   \n",
       "\n",
       "                                          True Answer  \\\n",
       "38  Manual task management methods allow either fo...   \n",
       "19  When it has been successfully matched to one o...   \n",
       "8   Load test is the objective is to ensure that l...   \n",
       "79  The primary objective of initiating the disput...   \n",
       "86  The unaccounted events dashboard will appear u...   \n",
       "85  It could change to be a business rule in advan...   \n",
       "61                 Is settled by a specific acquirers   \n",
       "53  Under the name unaccounted events and will be ...   \n",
       "43  The account, the account name, signing, amount...   \n",
       "30                                               Sftp   \n",
       "\n",
       "                                     Predicted Answer  BLEU Score  \\\n",
       "38  Allow either for operators to pick tasks from ...    0.878788   \n",
       "19  When it has been successfully matched to one o...    0.392857   \n",
       "8   Load test is the objective is to ensure that l...    0.963640   \n",
       "79  This step aims to facilitate a negotiation or ...    0.583333   \n",
       "86  In the second position under the accounting ma...    0.375000   \n",
       "85              It could change to be a business rule    0.727273   \n",
       "61                    Settled by a specific acquirers    0.833333   \n",
       "53    Second position under the accounting main title    0.388889   \n",
       "43  The account, the account name, signing, amount...    1.000000   \n",
       "30                                               Sftp    1.000000   \n",
       "\n",
       "    ROUGE-2 Score  \n",
       "38       0.928571  \n",
       "19       0.555556  \n",
       "8        1.000000  \n",
       "79       0.666667  \n",
       "86       0.516129  \n",
       "85       0.823529  \n",
       "61       0.888889  \n",
       "53       0.521739  \n",
       "43       1.000000  \n",
       "30       1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "df = pd.read_csv('output2.csv')\n",
    "\n",
    "# Randomly select five rows\n",
    "num_samples = 10\n",
    "random_indices = random.sample(range(len(df)), num_samples)\n",
    "random_rows = df.iloc[random_indices]\n",
    "\n",
    "random_rows.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7f0885",
   "metadata": {},
   "source": [
    "# Checking duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8817793e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated Rows:\n",
      "Empty DataFrame\n",
      "Columns: [Question, True Answer, Predicted Answer, BLEU Score, ROUGE-2 Score]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "duplicated_rows = df[df.duplicated()]\n",
    "\n",
    "# Display duplicated rows\n",
    "print(\"Duplicated Rows:\")\n",
    "print(duplicated_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fceec26",
   "metadata": {},
   "source": [
    "# Creating dataframe for comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1137969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of model names and their respective CSV files with pre-calculated scores\n",
    "model_files = {\n",
    "    'ALBERT': 'output2.csv',\n",
    "    'BERT': 'output1.csv',\n",
    "    'T5': 'output3.csv'\n",
    "}\n",
    "\n",
    "# Initialize lists to store data\n",
    "model_names = []\n",
    "avg_bleu_scores = []\n",
    "avg_rouge_scores = []\n",
    "\n",
    "# Calculate average BLEU and ROUGE scores for each model\n",
    "for model, file in model_files.items():\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    avg_bleu = df['BLEU Score'].mean()\n",
    "    avg_rouge = df['ROUGE-2 Score'].mean()\n",
    "    \n",
    "    model_names.append(model)\n",
    "    avg_bleu_scores.append(avg_bleu)\n",
    "    avg_rouge_scores.append(avg_rouge)\n",
    "\n",
    "# Create a new DataFrame with the aggregated data\n",
    "result_df = pd.DataFrame({\n",
    "    'Model name': model_names,\n",
    "    'AVG BLEU score': avg_bleu_scores,\n",
    "    'AVG ROUGE-2 score': avg_rouge_scores\n",
    "})\n",
    "\n",
    "# Save the new dataset to a CSV file\n",
    "result_df.to_csv('model_comparison.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6c28b5",
   "metadata": {},
   "source": [
    "# Final final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74365b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model name</th>\n",
       "      <th>AVG BLEU score</th>\n",
       "      <th>AVG ROUGE-2 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALBERT</td>\n",
       "      <td>0.711513</td>\n",
       "      <td>0.777917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BERT</td>\n",
       "      <td>0.404006</td>\n",
       "      <td>0.373474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>0.505599</td>\n",
       "      <td>0.602931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model name  AVG BLEU score  AVG ROUGE-2 score\n",
       "0     ALBERT        0.711513           0.777917\n",
       "1       BERT        0.404006           0.373474\n",
       "2         T5        0.505599           0.602931"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmp=pd.read_csv('model_comparison.csv')\n",
    "cmp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca25880",
   "metadata": {},
   "source": [
    "# Final final result using tabulate form\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58c9ef6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+------------------+---------------------+\n",
      "|    | Model name   |   AVG BLEU score |   AVG ROUGE-2 score |\n",
      "+====+==============+==================+=====================+\n",
      "|  0 | ALBERT       |         0.711513 |            0.777917 |\n",
      "+----+--------------+------------------+---------------------+\n",
      "|  1 | BERT         |         0.404006 |            0.373474 |\n",
      "+----+--------------+------------------+---------------------+\n",
      "|  2 | T5           |         0.505599 |            0.602931 |\n",
      "+----+--------------+------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "#importing the dataframe\n",
    "cmp_final1=pd.read_csv('model_comparison.csv')\n",
    "# Convert DataFrame to a formatted table with lines between columns\n",
    "formatted_table1 = tabulate(cmp_final1, headers='keys', tablefmt='grid')\n",
    "\n",
    "# Print the formatted table\n",
    "print(formatted_table1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
